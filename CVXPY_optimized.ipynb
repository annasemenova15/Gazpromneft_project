{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a23f202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cvxpy in /Users/anya/.local/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /Users/anya/.local/lib/python3.8/site-packages (from cvxpy) (0.6.2.post8)\n",
      "Requirement already satisfied: ecos>=2 in /Users/anya/.local/lib/python3.8/site-packages (from cvxpy) (2.0.12)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/anya/anaconda3/lib/python3.8/site-packages (from cvxpy) (1.6.2)\n",
      "Requirement already satisfied: setuptools>65.5.1 in /Users/anya/.local/lib/python3.8/site-packages (from cvxpy) (67.6.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/anya/anaconda3/lib/python3.8/site-packages (from cvxpy) (1.20.1)\n",
      "Requirement already satisfied: scs>=1.1.6 in /Users/anya/.local/lib/python3.8/site-packages (from cvxpy) (3.2.2)\n",
      "Requirement already satisfied: qdldl in /Users/anya/.local/lib/python3.8/site-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "19a7141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import yaml\n",
    "import cvxpy as cp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2ad28358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SettingWithCopyWarning \n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c8b99ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    try:\n",
    "        with open('config_file.yaml') as f:\n",
    "            global constants\n",
    "            constants = yaml.safe_load(f)\n",
    "    except OSError as e:\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "238e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1272c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='data', index_col=0)\n",
    "real = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='реал', index_col=0)\n",
    "bandwidth = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='ПС', index_col=0)\n",
    "match = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='match', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fe87b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict of names on a spreadsheets that we are going to use\n",
    "names = {\"Тариф ж/д\" : \"t1\",\n",
    "        \"Тариф хранение\" : \"t2\",\n",
    "        \"Тариф бренд\" : \"t3\",\n",
    "        \"Тариф ВЛ\" : \"t4\",\n",
    "        \"Плечо, км\" : \"distance\",\n",
    "        \"Дата\" : \"date\",\n",
    "        \"НБ\" : \"origin\",\n",
    "        \"ОУ\" : \"point\",\n",
    "        \"НГ\" : \"brand\",\n",
    "        \"НГ_ПС\" : \"product\",\n",
    "        \"Объем\" : \"volume\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2eca7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the names in dataframes\n",
    "def rename_columns(df_list, names):\n",
    "    for df in df_list:\n",
    "        df.rename(columns=names, inplace=True)\n",
    "\n",
    "# Add the column with the tariff\n",
    "def add_tariff(df):\n",
    "    df['cost'] = df['t1'] + df['t2'] + df['t3'] + df['t4']\n",
    "    df.loc[df['distance'] > 50, 'cost'] = df[\"t1\"] + df[\"t2\"] + df[\"t3\"] +  df[\"t4\"] * df[\"distance\"]\n",
    "\n",
    "# Make subset for the concrete time period\n",
    "def select_time_period(df):\n",
    "    df_subset = df[df['date'] == datetime.strptime(constants['MONTH'], '%Y-%m-%d')]\n",
    "    return df_subset\n",
    "\n",
    "# Adjust datatypes\n",
    "def adjust_datatypes(df_list):\n",
    "    for df in df_list:\n",
    "        if 'origin' in df.columns:\n",
    "            df['origin'] = df['origin'].map(lambda x: int(x.strip('Нефтебаза ')))\n",
    "        if 'point' in df.columns:\n",
    "            df['point'] = df['point'].map(lambda x: int(x.strip('АЗС ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "99bace36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes to dataframes\n",
    "def apply_changes_dfs(data, real, bandwidth, match, names):\n",
    "    rename_columns([data, real, bandwidth, match], names)\n",
    "    add_tariff(data)\n",
    "    \n",
    "    data_subset = select_time_period(data)\n",
    "    real_subset = select_time_period(real)\n",
    "    bandwidth_subset = select_time_period(bandwidth)\n",
    "\n",
    "    adjust_datatypes([data_subset,real_subset, bandwidth_subset])\n",
    "    \n",
    "    return data_subset, real_subset, bandwidth_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "50bd659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset, real_subset, bandwidth_subset = apply_changes_dfs(data, real, bandwidth, match, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f86705a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brand-product dict\n",
    "def create_brand_product_dict(df):\n",
    "    match_brand_product = dict(zip(df['brand'], df['product']))\n",
    "    \n",
    "    match_product_brand = dict()\n",
    "    for key, value in match_brand_product.items():\n",
    "        match_product_brand.setdefault(value, list()).append(key)\n",
    "    return match_brand_product, match_product_brand\n",
    "\n",
    "# Create numeration dict and inverted dict\n",
    "def create_numeration_dict(df, parameter):\n",
    "    match_dict = dict(enumerate(df[parameter]))\n",
    "    inv_dict = {v: k for k, v in match_dict.items()}\n",
    "    return match_dict, inv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "734f9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 6 dictionaries (brand-product, brand-number, product-number, and inverted)\n",
    "match_brand_product, match_product_brand = create_brand_product_dict(match)\n",
    "match_brand_number, match_number_brand = create_numeration_dict(match,'brand')\n",
    "match_product_number, match_number_product = create_numeration_dict(match,'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "25063419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create name of variable\n",
    "def create_var_Name(row):\n",
    "    var_name = 'P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])) +  '_brand_' + str(int(row[\"brand_number\"]))\n",
    "    return var_name\n",
    "\n",
    "# Reorganize the data\n",
    "def reorganize_df(df, columns_to_keep, match_number_brand, match_number_product):\n",
    "    df_reorganized = df.reset_index().loc[:, columns_to_keep]\n",
    "    df_reorganized['brand_number'] = df_reorganized['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    df_reorganized['product_number'] = df_reorganized['product'].map(lambda x: match_number_product.get(x))\n",
    "    \n",
    "    return df_reorganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1fcaa7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['origin', 'point', 'brand', 'product', 'cost']\n",
    "df_reorganized = reorganize_df(data_subset, columns_to_keep, match_number_brand, match_number_product)\n",
    "\n",
    "# Create a name variable\n",
    "df_reorganized['var_Name'] = df_reorganized.apply(lambda row: create_var_Name(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f5a7466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demand df\n",
    "def create_demand_supply_dfs(real, bandwidth):\n",
    "    demand = real[['point', 'brand', 'product', 'volume']]\n",
    "    demand.rename(columns={'volume':'demand'}, inplace=True)\n",
    "    demand['brand_number'] = demand['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    demand['product_number'] = demand['product'].map(lambda x: match_number_product.get(x))\n",
    "    \n",
    "    supply = bandwidth[['origin', 'product', 'volume']]\n",
    "    supply.rename(columns={'volume':'supply'}, inplace=True)\n",
    "    supply['product_number'] = supply['product'].map(lambda x: match_number_product.get(x))\n",
    "    \n",
    "    return demand, supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c6bc5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, supply = create_demand_supply_dfs(real_subset, bandwidth_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a52ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1725aeac",
   "metadata": {},
   "source": [
    "# CVXPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "770e9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = df_reorganized['brand_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "89528ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_reorganized\n",
    "\n",
    "brand_info_map = {}\n",
    "\n",
    "def make_brand(brand_id, name):\n",
    "    return {'name': name, 'id': brand_id, 'product_transportations': {}}\n",
    "\n",
    "def make_transportation(origin, point, cost, var_name):\n",
    "    return {'origin': origin, 'point': point, 'cost': cost, 'var_name': var_name}\n",
    "\n",
    "def add_transportation_to_brand(brand, product_id, transportation):\n",
    "    if brand['product_transportations'].get(product_id) == None:\n",
    "        brand['product_transportations'][product_id] = [transportation];\n",
    "        return brand;\n",
    "    \n",
    "    brand['product_transportations'].get(product_id).append(transportation);    \n",
    "\n",
    "    return brand;\n",
    "\n",
    "\n",
    "def append_row_to_map(brand_map, row, index):\n",
    "    brand_id = row['brand_number'];\n",
    "    \n",
    "    if brand_map.get(brand_id) == None:\n",
    "        brand_map[brand_id] = make_brand(brand_id, row['brand']);\n",
    "        \n",
    "    brand_item = brand_map.get(brand_id);\n",
    "    product_id = row['product_number'];\n",
    "    \n",
    "    transportation = make_transportation(row['origin'], row['point'], row['cost'], index);\n",
    "    brand_map[brand_id] = add_transportation_to_brand(brand_item, product_id, transportation)\n",
    "    \n",
    "    return brand_map\n",
    "\n",
    "for i, row in df_reorganized.iterrows():\n",
    "    brand_info_map = append_row_to_map(brand_info_map, row, i);\n",
    "\n",
    "json_formatted_str = json.dumps(brand_info_map, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1249dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different brands\n",
    "def merge_supply(brand_number, match_brand_product, match_brand_number, match_product_brand, match_number_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    product_name = match_brand_product[brand_name]\n",
    "    brands_overlap_names = match_product_brand[product_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cb6238a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_problem(df):\n",
    "    x = cp.Variable(len(df), nonneg = True)\n",
    "    c = np.array(df['cost'])\n",
    "    objective = cp.Minimize(c.T @ x)\n",
    "    \n",
    "    return x, objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "07a95405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_points_of_brand(brand):\n",
    "    points = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            points.append(transportation.get('point'))\n",
    "\n",
    "    points = list(set(points))\n",
    "    \n",
    "    return points\n",
    "\n",
    "def extract_unique_origins_of_brand(brand):\n",
    "    origins = []\n",
    "    for transportations in brand.get('product_transportations').values():\n",
    "        for transportation in transportations:\n",
    "            origins.append(transportation.get('origin'))\n",
    "\n",
    "    origins = list(set(origins))\n",
    "    \n",
    "    return origins\n",
    "\n",
    "def get_brand_transportations(brand):\n",
    "    brand_transpotrations = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            brand_transpotrations.append(transportation)\n",
    "                \n",
    "    return brand_transpotrations\n",
    "\n",
    "def extract_unique_origins(brand_map):\n",
    "    origins = []\n",
    "    for brand in brand_map.values():\n",
    "        origins = origins + extract_unique_origins_of_brand(brand)\n",
    "\n",
    "    return list(set(origins))\n",
    "\n",
    "def extract_unique_points(brand_map):\n",
    "    points = []\n",
    "    for brand in brand_map.values():\n",
    "        points = points + extract_unique_points_of_brand(brand)\n",
    "        \n",
    "    return list(set(points))\n",
    "\n",
    "def get_transportations(brand_map):\n",
    "    transportations = []\n",
    "    \n",
    "    for brand in brand_map.values():\n",
    "        transportations = transportations + get_brand_transportations(brand)\n",
    "        \n",
    "    return transportations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b83a54",
   "metadata": {},
   "source": [
    "#### Define restriction #1: demand equals const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa19466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_demand(record, brands, x, demand):\n",
    "    n_constraint = 1\n",
    "    constraints = []\n",
    "    \n",
    "    for brand_id in brands:\n",
    "        brand = record.get(brand_id);\n",
    "        points = extract_unique_points_of_brand(brand)\n",
    "    \n",
    "        for p in points:\n",
    "            transportations = get_brand_transportations(brand)\n",
    "            brand_point_transpotrations = [transportation for transportation in transportations if transportation.get('point') == p]\n",
    "            \n",
    "            const = float(demand[(demand['point'] == p) & (demand['brand_number'] == brand_id)]['demand'])\n",
    "            transportations_x = [x[transportation.get('var_name')] for transportation in brand_point_transpotrations]\n",
    "            constraints.append(cp.sum(transportations_x) == const)\n",
    "            n_constraint +=1\n",
    "        \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83561da8",
   "metadata": {},
   "source": [
    "#### Define restriction #2: supply less or equal than const;  restriction #4: supply greater or equal to const * percent_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b5b51a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_supply(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply(b, match_brand_product, match_brand_number, match_product_brand, match_number_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            if o in origins_with_inf_supply:\n",
    "                continue\n",
    "\n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'] == product_name)]['supply'])\n",
    "\n",
    "            # Add a restriction on supply <= upper_const\n",
    "            transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "            constraints.append(cp.sum(transportation_x) <= const)\n",
    "            n_constraint +=1\n",
    "\n",
    "            # Add a restriction on supply >= lower_const\n",
    "            const *= constants['PERCENT_LOADING']\n",
    "            transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "            constraints.append(cp.sum(transportation_x) >= const)\n",
    "            n_constraint +=1 \n",
    "                    \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c5cbc",
   "metadata": {},
   "source": [
    "#### Define restriction #3: all brands for one point should come from the same origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "58b81ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_Name(row):\n",
    "    return 'y_P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])), int(row[\"point\"]), int(row[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "43b311c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_dummy(df, x, constraints, n_constraint):\n",
    "    [*o] = df.apply(lambda row: create_dummy_Name(row), axis=1)\n",
    "    df_dummies = pd.DataFrame(o, columns=['dummy_Name', 'point', 'origin'])\n",
    "    df_dummies = df_dummies.reset_index()\n",
    "    df_dummies = df_dummies.drop_duplicates(subset=['dummy_Name', 'point', 'origin'])\n",
    "    dummies = cp.Variable(len(df_dummies), boolean=True)\n",
    "    \n",
    "    df_dummies.reset_index(inplace=True)\n",
    "    df_dummies.drop(columns=['index', 'level_0'], inplace=True)\n",
    "    \n",
    "    points = df['point'].unique()\n",
    "    origins = df['origin'].unique()\n",
    "\n",
    "    for p in points:\n",
    "        for o in origins:\n",
    "            df1 = df[(df['point'] == p) & (df['origin'] == o)]\n",
    "            df_d = df_dummies[(df_dummies['point'] == p) & (df_dummies['origin'] == o)]\n",
    "            constraints.append(cp.sum(x[df1.index]) <= constants['M'] * dummies[df_d.index])\n",
    "            n_constraint += 1\n",
    "    \n",
    "    const = 1     \n",
    "    for p in points:\n",
    "        df_d = df_dummies[df_dummies['point'] == p]\n",
    "        constraints.append(cp.sum(dummies[df_d.index]) == const)\n",
    "        n_constraint += 1\n",
    "\n",
    "\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5dd9b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, objective = define_problem(df_reorganized)\n",
    "constraints, n_constraint, x = make_restriction_demand(brand_info_map, brands, x, demand)\n",
    "constraints, n_constraint, x = make_restriction_supply(constraints, brand_info_map, bandwidth_subset, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint)\n",
    "constraints = make_restriction_dummy(df_reorganized, x, constraints, n_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495eb60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "64297fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(objective, constraints):\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "41288492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.3.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Apr 23 10:20:19 PM: Your problem has 458 variables, 335 constraints, and 0 parameters.\n",
      "(CVXPY) Apr 23 10:20:19 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 23 10:20:19 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Apr 23 10:20:19 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 23 10:20:19 PM: Compiling problem (target solver=COPT).\n",
      "(CVXPY) Apr 23 10:20:19 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> COPT\n",
      "(CVXPY) Apr 23 10:20:19 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 23 10:20:20 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 23 10:20:20 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Apr 23 10:20:20 PM: Applying reduction COPT\n",
      "(CVXPY) Apr 23 10:20:20 PM: Finished problem compilation (took 1.040e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 23 10:20:20 PM: Invoking solver COPT  to obtain a solution.\n",
      "Cardinal Optimizer v6.0.5. Build date Feb  7 2023\n",
      "Copyright Cardinal Operations 2022. All Rights Reserved\n",
      "\n",
      "Setting parameter 'Logging' to 1\n",
      "No license found. The size is limited to 2000 variables and 2000 constraints\n",
      "Please apply for a license from www.shanshu.ai/copt\n",
      "\n",
      "Model fingerprint: 42d4c311\n",
      "\n",
      "Using Cardinal Optimizer v6.0.5 on macOS\n",
      "Hardware has 2 cores and 4 threads. Using instruction set X86_AVX2 (10)\n",
      "Minimizing a MIP problem\n",
      "\n",
      "The original problem has:\n",
      "    793 rows, 458 columns and 1734 non-zero elements\n",
      "    98 binaries\n",
      "\n",
      "Presolving the problem\n",
      "\n",
      "The presolved problem has:\n",
      "    8 rows, 49 columns and 298 non-zero elements\n",
      "    49 binaries\n",
      "\n",
      "Starting the MIP solver with 4 threads and 8 tasks\n",
      "\n",
      "     Nodes    Active  LPit/n  IntInf     BestBound  BestSolution    Gap   Time\n",
      "         0         1      --       0  7.423747e+07            --    Inf  0.10s\n",
      "H        0         1      --       0  7.423747e+07  8.808565e+07  15.7%  0.11s\n",
      "H        0         1      --       0  7.423747e+07  8.684851e+07  14.5%  0.11s\n",
      "         0         1      --       4  8.439709e+07  8.684851e+07  2.82%  0.12s\n",
      "H        0         1      --       4  8.439709e+07  8.507208e+07  0.79%  0.12s\n",
      "H        0         1      --       4  8.439709e+07  8.483675e+07  0.52%  0.12s\n",
      "H        0         1      --       4  8.439709e+07  8.477606e+07  0.45%  0.17s\n",
      "H        0         1      --       4  8.439709e+07  8.452905e+07  0.16%  0.17s\n",
      "         0         1      --       4  8.439709e+07  8.452905e+07  0.16%  0.17s\n",
      "         1         2     0.0       4  8.439837e+07  8.452905e+07  0.15%  0.19s\n",
      "H        1         0    37.0      12  8.440485e+07  8.447109e+07  0.08%  0.31s\n",
      "         2         2    18.5      12  8.440485e+07  8.447109e+07  0.08%  0.31s\n",
      "         3         2    17.0       8  8.440485e+07  8.447109e+07  0.08%  0.32s\n",
      "         4         4    13.2      11  8.440485e+07  8.447109e+07  0.08%  0.32s\n",
      "         5         1    12.0       4  8.440605e+07  8.447109e+07  0.08%  0.32s\n",
      "\n",
      "     Nodes    Active  LPit/n  IntInf     BestBound  BestSolution    Gap   Time\n",
      "         6         3    12.2       3  8.440605e+07  8.447109e+07  0.08%  0.33s\n",
      "         7         5    10.7       5  8.440605e+07  8.447109e+07  0.08%  0.33s\n",
      "         8         7     9.9       9  8.440605e+07  8.447109e+07  0.08%  0.33s\n",
      "         9         2     8.9       3  8.440628e+07  8.447109e+07  0.08%  0.33s\n",
      "        10         4     8.6       4  8.440628e+07  8.447109e+07  0.08%  0.34s\n",
      "        20        14     6.7       3  8.440724e+07  8.447109e+07  0.08%  0.34s\n",
      "        30        26     6.3       4  8.440731e+07  8.447109e+07  0.08%  0.34s\n",
      "        40        30     5.7       3  8.440831e+07  8.447109e+07  0.07%  0.35s\n",
      "        50        40     5.3       4  8.440831e+07  8.447109e+07  0.07%  0.36s\n",
      "        60        50     5.0       5  8.440831e+07  8.447109e+07  0.07%  0.37s\n",
      "        70        56     4.7       3  8.440831e+07  8.447109e+07  0.07%  0.38s\n",
      "        80        56     4.4       7  8.441004e+07  8.447109e+07  0.07%  0.38s\n",
      "        90        60     4.4       7  8.441282e+07  8.447109e+07  0.07%  0.39s\n",
      "       100        70     4.2       3  8.441598e+07  8.447109e+07  0.07%  0.40s\n",
      "       110        75     4.1       3  8.441702e+07  8.447109e+07  0.06%  0.40s\n",
      "\n",
      "     Nodes    Active  LPit/n  IntInf     BestBound  BestSolution    Gap   Time\n",
      "       120        76     4.0       3  8.441938e+07  8.447109e+07  0.06%  0.41s\n",
      "       130        82     4.0       3  8.441963e+07  8.447109e+07  0.06%  0.41s\n",
      "       140        88     3.8       6  8.442113e+07  8.447109e+07  0.06%  0.41s\n",
      "       150        92     3.9       3  8.442358e+07  8.447109e+07  0.06%  0.42s\n",
      "       160        88     3.7       3  8.442358e+07  8.447109e+07  0.06%  0.42s\n",
      "       170        94     3.6       3  8.442358e+07  8.447109e+07  0.06%  0.42s\n",
      "       180       100     3.6       4  8.442485e+07  8.447109e+07  0.05%  0.43s\n",
      "H      183       104     3.6       4  8.442485e+07  8.446654e+07  0.05%  0.43s\n",
      "       190       107     3.6       3  8.442485e+07  8.446654e+07  0.05%  0.43s\n",
      "H      194       105     3.5       2  8.442512e+07  8.446643e+07  0.05%  0.43s\n",
      "       200       107     3.5       3  8.442512e+07  8.446643e+07  0.05%  0.43s\n",
      "*      228       123     3.3       0  8.442512e+07  8.445232e+07  0.03%  0.44s\n",
      "       300        80     3.0       3  8.443408e+07  8.445232e+07  0.02%  0.45s\n",
      "H      325        66     2.8       1  8.443498e+07  8.445221e+07  0.02%  0.45s\n",
      "*      332        61     2.8       0  8.443507e+07  8.445167e+07  0.02%  0.45s\n",
      "\n",
      "     Nodes    Active  LPit/n  IntInf     BestBound  BestSolution    Gap   Time\n",
      "       400         0     2.4       4  8.445167e+07  8.445167e+07  0.00%  0.47s\n",
      "       403         0     2.4       3  8.445167e+07  8.445167e+07  0.00%  0.48s\n",
      "\n",
      "Best solution   : 84451667.329992369\n",
      "Best bound      : 84451667.329992399\n",
      "Best gap        : 0.0000%\n",
      "Solve time      : 0.49\n",
      "Solve node      : 403\n",
      "MIP status      : solved\n",
      "Solution status : integer optimal (relative gap limit 0.0001)\n",
      "\n",
      "Violations      :     absolute     relative\n",
      "  bounds        :            0            0\n",
      "  rows          :            0            0\n",
      "  integrality   :            0\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 23 10:20:21 PM: Problem status: optimal\n",
      "(CVXPY) Apr 23 10:20:21 PM: Optimal value: 8.445e+07\n",
      "(CVXPY) Apr 23 10:20:21 PM: Compilation took 1.040e+00 seconds\n",
      "(CVXPY) Apr 23 10:20:21 PM: Solver (including time spent in interface) took 5.824e-01 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8881e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
