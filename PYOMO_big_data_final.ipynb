{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19a7141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from pyomo.environ import *\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ad28358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SettingWithCopyWarning \n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dad71cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    try:\n",
    "        with open('config_file.yaml') as f:\n",
    "            global constants\n",
    "            constants = yaml.safe_load(f)\n",
    "    except OSError as e:\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3e93a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "676b339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "# File name is specified in config file\n",
    "data_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='data', engine='pyxlsb')\n",
    "real_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='Real', engine='pyxlsb')\n",
    "bandwidth_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='PS', engine='pyxlsb')\n",
    "match_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='match', engine='pyxlsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34a30b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets to implement further changes\n",
    "data = data_input.copy()\n",
    "real = real_input.copy()\n",
    "bandwidth = bandwidth_input.copy()\n",
    "match = match_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe87b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict of names on a spreadsheets that we are going to use\n",
    "names = {\"Тариф\" : \"cost\",\n",
    "        \"Плечо\" : \"distance\",\n",
    "        \"Дата\" : \"date\",\n",
    "        \"НБ\" : \"origin\",\n",
    "        \"ОУ\" : \"point\",\n",
    "        \"НП\" : \"brand\",\n",
    "        \"НП_ПС\" : \"product\",\n",
    "        \"Объем\" : \"volume\",\n",
    "        \"reg\": \"region\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2eca7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the names in dataframes\n",
    "def rename_columns(df_list, names):\n",
    "    for df in df_list:\n",
    "         df.rename(columns=names, inplace=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f83cb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, real, bandwidth, match = rename_columns([data, real, bandwidth, match], names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99bace36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated; will raise an error if there are duplicates\n",
    "assert data[data.duplicated(subset = ['point', 'origin', 'region', 'brand', 'date'])].empty == True\n",
    "assert real[real.duplicated(subset = ['point', 'brand', 'date'])].empty == True\n",
    "assert bandwidth[bandwidth.duplicated(subset = ['origin', 'product', 'date'])].empty == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af9f4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make subset for the concrete time period\n",
    "def select_time_period(df):\n",
    "    df_subset = df[df['date'] == constants['MONTH']]\n",
    "    return df_subset\n",
    "\n",
    "# Make subset for the concrete region - ONLY FOR EXPERIMENTS, IN THE FINAL VERSION ALL REGIONS GO TOGETHER\n",
    "def select_region(df):\n",
    "    regions_to_select = []\n",
    "    \n",
    "    for region_number in constants['REGION']:\n",
    "        region_name = 'Регион ' + str(region_number)\n",
    "        regions_to_select.append(region_name)\n",
    "        \n",
    "    if 'region' in df.columns:\n",
    "        df = df[(df['region'].isin(regions_to_select))]\n",
    "    return df\n",
    "    \n",
    "# Adjust datatypes. Enumerate oilbases and petrol stations      \n",
    "def adjust_datatypes(df_list):\n",
    "    df_new = []\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    for df in df_list:\n",
    "        if 'origin' in df.columns:\n",
    "            df = df.replace({\"origin\": oilbases_dict})\n",
    "        if 'point' in df.columns:\n",
    "            df['point'] = df['point'].map(lambda x: int(x.strip('АЗС ')))\n",
    "        df_new.append(df)\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf7130b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes to dataframes\n",
    "def apply_changes_dfs(data, real, bandwidth, match):\n",
    "    \n",
    "    data_subset = select_time_period(data)\n",
    "    real_subset = select_time_period(real)\n",
    "    bandwidth_subset = select_time_period(bandwidth)\n",
    "\n",
    "    data_subset = select_region(data_subset)\n",
    "\n",
    "    data_subset, real_subset, bandwidth_subset = adjust_datatypes([data_subset, real_subset, bandwidth_subset])\n",
    "    data_subset['cost'] = data_subset['cost'].round(4)\n",
    "    \n",
    "    return data_subset, real_subset, bandwidth_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c673cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset, real_subset, bandwidth_subset = apply_changes_dfs(data, real, bandwidth, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "535f603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brand-product dict\n",
    "def create_brand_product_dict(df):\n",
    "    match_brand_product = dict(zip(df['brand'], df['product']))\n",
    "    \n",
    "    match_product_brand = dict()\n",
    "    for key, value in match_brand_product.items():\n",
    "        match_product_brand.setdefault(value, list()).append(key)\n",
    "    return match_brand_product, match_product_brand\n",
    "\n",
    "# Create numeration dict and inverted dict\n",
    "def create_numeration_dict(df, parameter):\n",
    "    match_dict = dict(enumerate(df[parameter]))\n",
    "    inv_dict = {v: k for k, v in match_dict.items()}\n",
    "    return match_dict, inv_dict\n",
    "\n",
    "# Create numeration dict and inverted dict\n",
    "def create_prod_numeration_dict(df, parameter):\n",
    "    match_dict = dict(enumerate(df[parameter].unique()))\n",
    "    inv_dict = {v: k for k, v in match_dict.items()}\n",
    "    return match_dict, inv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0790b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 6 dictionaries (brand-product, brand-number, product-number, and inverted)\n",
    "match_brand_product, match_product_brand = create_brand_product_dict(match)\n",
    "match_brand_number, match_number_brand = create_numeration_dict(match,'brand')\n",
    "match_product_number, match_number_product = create_prod_numeration_dict(match,'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b779753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create name of variable\n",
    "def create_var_Name(row):\n",
    "    var_name = 'P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])) +  '_brand_' + str(int(row[\"brand_number\"]))\n",
    "    return var_name\n",
    "\n",
    "# Reorganize the data. Select only specified columns, enumerate brands and products\n",
    "def reorganize_df(df, columns_to_keep, match_number_brand, match_number_product):\n",
    "    df_reorganized = df.reset_index().loc[:, columns_to_keep]\n",
    "    df_reorganized['brand_number'] = df_reorganized['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    df_reorganized['product_number'] = df_reorganized['product'].map(lambda x: match_number_product.get(x))\n",
    "    \n",
    "    return df_reorganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc1a7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['origin', 'point', 'brand', 'date', 'product', 'cost', 'region']\n",
    "df_reorganized = reorganize_df(data_subset, columns_to_keep, match_number_brand, match_number_product)\n",
    "\n",
    "# Create a name variable\n",
    "df_reorganized['var_Name'] = df_reorganized.apply(lambda row: create_var_Name(row), axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc2b22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demand and supply dataframes\n",
    "# Demand - volume of each product needed to be transported to the point\n",
    "# Supply - volume of each product available on the origin\n",
    "\n",
    "def create_demand_supply_dfs(real, bandwidth):\n",
    "    demand = real[['point', 'brand', 'product', 'volume', 'date']]\n",
    "    demand.rename(columns={'volume':'demand'}, inplace=True)\n",
    "    demand['brand_number'] = demand['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    demand['product_number'] = demand['product'].map(lambda x: match_number_product.get(x))\n",
    "    demand['demand'] = demand['demand'].round(4)\n",
    "    \n",
    "    supply = bandwidth[['origin', 'product', 'volume', 'date']]\n",
    "    supply.rename(columns={'volume':'supply'}, inplace=True)\n",
    "    supply['product_number'] = supply['product'].map(lambda x: match_number_product.get(x))\n",
    "    supply['supply'] = supply['supply'].round(4)\n",
    "    \n",
    "    return demand, supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84a2bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, supply = create_demand_supply_dfs(real_subset, bandwidth_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2de469be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit demand and supply with only needed origins and points\n",
    "supply = supply[supply['origin'].isin(df_reorganized.origin.unique())]\n",
    "demand = demand[demand['point'].isin(df_reorganized.point.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b582bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df_reorganized:  7716\n",
      "Length of new df_reorganized:  5729\n",
      "\n",
      "Number of pairs of origins-product dropped:  6\n",
      "Number of pairs of points-brands:  0\n"
     ]
    }
   ],
   "source": [
    "# Make a copy\n",
    "df_reorganized_trans = df_reorganized.copy()\n",
    "print('Length of original df_reorganized: ', len(df_reorganized))\n",
    "\n",
    "# Check for where ALL volumes equals == 0 \n",
    "df_trans= supply[supply['supply'] <= 0][['origin', 'product_number']]\n",
    "origins_zero_volume = set(zip(df_trans.origin, df_trans.product_number))\n",
    "\n",
    "pairs_origins_products_to_delete = []\n",
    "pairs_points_brands_to_delete = []\n",
    "\n",
    "# Filter df_reogranized\n",
    "for _, row in df_reorganized.iterrows():\n",
    "\n",
    "    origin, point, product, brand = row['origin'], row['point'], row['product_number'], row['brand_number']\n",
    "    \n",
    "    if supply[(supply['origin'] == origin) & (supply['product_number'] == product)].empty:\n",
    "        pairs_origins_products_to_delete.append((origin, product))\n",
    "\n",
    "    if demand[(demand['point'] == point) & (demand['brand_number'] == brand)].empty:\n",
    "        pairs_points_brands_to_delete.append((point, brand))\n",
    "\n",
    "pairs_origins_products_to_delete = set(pairs_origins_products_to_delete)\n",
    "pairs_points_brands_to_delete = set(pairs_points_brands_to_delete)\n",
    "\n",
    "# Update origins to delete\n",
    "pairs_origins_products_to_delete.update(origins_zero_volume)\n",
    "\n",
    "df_reorganized_trans['origin_product'] = list(zip(df_reorganized_trans.origin, df_reorganized_trans.product_number))\n",
    "df_reorganized_trans['point_brand'] = list(zip(df_reorganized_trans.point, df_reorganized_trans.brand_number))\n",
    "  \n",
    "df_reorganized_trans = df_reorganized_trans.drop(df_reorganized_trans[df_reorganized_trans['origin_product'].isin(pairs_origins_products_to_delete)].index)\n",
    "df_reorganized_trans = df_reorganized_trans.drop(df_reorganized_trans[df_reorganized_trans['point_brand'].isin(pairs_points_brands_to_delete)].index)\n",
    "   \n",
    "        \n",
    "# Reassign df\n",
    "df_reorganized = df_reorganized_trans\n",
    "df_reorganized = df_reorganized.reset_index().drop('index', axis=1)\n",
    "print('Length of new df_reorganized: ', len(df_reorganized))\n",
    "\n",
    "print('\\nNumber of pairs of origins-product dropped: ', len(pairs_origins_products_to_delete))\n",
    "print('Number of pairs of points-brands: ', len(pairs_points_brands_to_delete))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725aeac",
   "metadata": {},
   "source": [
    "# Pyomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2184cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = df_reorganized['brand_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a79ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_info_map = {}\n",
    "\n",
    "def make_brand(brand_id, name):\n",
    "    return {'name': name, 'id': brand_id, 'product_transportations': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7fbab0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transportation(origin, point, cost, var_name):\n",
    "    return {'origin': origin, 'point': point, 'cost': cost, 'var_name': var_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cda9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transportation_to_brand(brand, product_id, transportation):\n",
    "    if brand['product_transportations'].get(product_id) == None:\n",
    "        brand['product_transportations'][product_id] = [transportation]\n",
    "        return brand\n",
    "    \n",
    "    brand['product_transportations'].get(product_id).append(transportation)  \n",
    "\n",
    "    return brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05388c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row_to_map(brand_map, row, index):\n",
    "    brand_id = row['brand_number']\n",
    "    \n",
    "    if brand_map.get(brand_id) == None:\n",
    "        brand_map[brand_id] = make_brand(brand_id, row['brand'])\n",
    "        \n",
    "    brand_item = brand_map.get(brand_id)\n",
    "    product_id = row['product_number']\n",
    "    \n",
    "    transportation = make_transportation(row['origin'], row['point'], row['cost'], index)\n",
    "    brand_map[brand_id] = add_transportation_to_brand(brand_item, product_id, transportation)\n",
    "    \n",
    "    return brand_map\n",
    "\n",
    "for i, row in df_reorganized.iterrows():\n",
    "    brand_info_map = append_row_to_map(brand_info_map, row, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de13eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dumps(brand_info_map, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea6426c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dicts for groups - either D (diesel) or P (petrol)\n",
    "def make_match_dicts(match_brand_product):\n",
    "    \n",
    "    match_brand_group = dict()\n",
    "    match_product_group = dict()\n",
    "\n",
    "    for k,v in match_brand_product.items():\n",
    "        if \"ДТ\" in v:\n",
    "            match_brand_group[k] = \"D\"\n",
    "            match_product_group[v] = \"D\"\n",
    "        \n",
    "        elif (\"АИ\" in v) | (\"Аи\" in v):\n",
    "            match_brand_group[k] = \"P\"\n",
    "            match_product_group[v] = \"P\"\n",
    "\n",
    "    match_group_brand = dict()\n",
    "\n",
    "    for k,v in match_brand_group.items():\n",
    "        match_group_brand.setdefault(v, list()).append(k)\n",
    "    \n",
    "    \n",
    "    match_group_product = dict()\n",
    "\n",
    "    for k,v in match_product_group.items():\n",
    "        match_group_product.setdefault(v, list()).append(k)\n",
    "    \n",
    "    return match_brand_group, match_product_group, match_group_brand, match_group_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7e1e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_brand_group, match_product_group, match_group_brand, match_group_product = make_match_dicts(match_brand_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d978098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different products\n",
    "def merge_supply_by_product(brand_number, match_brand_product, match_brand_number, match_product_brand, match_number_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    product_name = match_brand_product[brand_name]\n",
    "    brands_overlap_names = match_product_brand[product_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a2e383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different groups\n",
    "def merge_supply_by_group(brand_number, match_brand_number, match_number_brand, match_brand_group, match_group_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product group - P or D\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    group_name = match_brand_group[brand_name]\n",
    "    brands_overlap_names = match_group_brand[group_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1567def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different brands\n",
    "def merge_supply(brand_number, match_brand_product, match_brand_number, match_product_brand, match_number_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    product_name = match_brand_product[brand_name]\n",
    "    brands_overlap_names = match_product_brand[product_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdbfcc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique points inside each brand\n",
    "def extract_unique_points_of_brand(brand):\n",
    "    points = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            points.append(transportation.get('point'))\n",
    "\n",
    "    points = list(set(points))\n",
    "    \n",
    "    return points\n",
    "\n",
    "# Get the list of unique origins inside each brand\n",
    "def extract_unique_origins_of_brand(brand):\n",
    "    origins = []\n",
    "    for transportations in brand.get('product_transportations').values():\n",
    "        for transportation in transportations:\n",
    "            origins.append(transportation.get('origin'))\n",
    "\n",
    "    origins = list(set(origins))\n",
    "    \n",
    "    return origins\n",
    "\n",
    "# Extract the transportation of products from map dictionary\n",
    "def get_brand_transportations(brand):\n",
    "    brand_transpotrations = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            brand_transpotrations.append(transportation)\n",
    "                \n",
    "    return brand_transpotrations\n",
    "\n",
    "# Get the list of unique origins (overall)\n",
    "def extract_unique_origins(brand_map):\n",
    "    origins = []\n",
    "    for brand in brand_map.values():\n",
    "        origins = origins + extract_unique_origins_of_brand(brand)\n",
    "\n",
    "    return list(set(origins))\n",
    "\n",
    "# Get the list of unique points (overall)\n",
    "def extract_unique_points(brand_map):\n",
    "    points = []\n",
    "    for brand in brand_map.values():\n",
    "        points = points + extract_unique_points_of_brand(brand)\n",
    "        \n",
    "    return list(set(points))\n",
    "\n",
    "# Get transportations of concrete brand\n",
    "def get_transportations(brand_map):\n",
    "    transportations = []\n",
    "    \n",
    "    for brand in brand_map.values():\n",
    "        transportations = transportations + get_brand_transportations(brand)\n",
    "        \n",
    "    return transportations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "348b04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_problem(df):\n",
    "    model = ConcreteModel()\n",
    "    model.x = Var(range(len(df)), domain=Reals, bounds=(0.0,None))\n",
    "    c = np.array(df['cost'])\n",
    "    obj_expr = sum(c[i] * model.x[i] for i in model.x)\n",
    "    \n",
    "    return model, obj_expr, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "952c7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_demand(record, model, demand, y, brands):\n",
    "    model.constraints = ConstraintList()\n",
    "    n_constraint = 1\n",
    "    \n",
    "    for brand_id in brands:\n",
    "        brand = record.get(brand_id)\n",
    "        points = extract_unique_points_of_brand(brand)\n",
    "    \n",
    "        for p in points:\n",
    "            transportations = get_brand_transportations(brand)\n",
    "            brand_point_transpotrations = [transportation for transportation in transportations if transportation.get('point') == p]\n",
    "            const = float(demand[(demand['point'] == p) & (demand['brand_number'] == brand_id)]['demand'])\n",
    "            \n",
    "            # Add a restriction on demand == const\n",
    "            expr = sum([y[transportation.get(\"var_name\")] for transportation in brand_point_transpotrations])\n",
    "            model.constraints.add(expr == const)\n",
    "            n_constraint +=1\n",
    "        \n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70ae71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_supply_by_group_upper(model, record, bandwidth, supply, y, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    #origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_group(b, match_brand_number, match_number_brand, match_brand_group, match_group_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            group_name = match_product_group[product_name]\n",
    "            products_share_group = match_group_product[group_name]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'].isin(products_share_group))]['supply'].sum())\n",
    "\n",
    "            # Add a restriction on supply <= upper_const\n",
    "            model.constraints.add(sum(y[transportation.get(\"var_name\")] for transportation in origin_transportations) <= const)\n",
    "            n_constraint +=1\n",
    "                    \n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88a7c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_supply_by_group_lower(model, record, bandwidth, supply, y, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_group(b, match_brand_number, match_number_brand, match_brand_group, match_group_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            group_name = match_product_group[product_name]\n",
    "            products_share_group = match_group_product[group_name]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'].isin(products_share_group))]['supply'].sum())            \n",
    "            \n",
    "            if o in origins_with_inf_supply:\n",
    "                continue       \n",
    "\n",
    "            else:\n",
    "                # Add a restriction on supply >= lower_const\n",
    "                const *= constants['PERCENT_LOADING']\n",
    "                model.constraints.add(sum(y[transportation.get(\"var_name\")] for transportation in origin_transportations) >= const)\n",
    "                n_constraint +=1 \n",
    "                    \n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c1b8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation by month and product - upper bound\n",
    "def make_restriction_supply_by_product_upper(model, record, bandwidth, supply, y, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    #origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_product(b, match_brand_product, match_brand_number, match_product_brand, match_number_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "            \n",
    "            \n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'] == product_name)]['supply'])\n",
    "            \n",
    "            # Add a restriction on supply <= upper_const\n",
    "            model.constraints.add(sum(y[transportation.get(\"var_name\")] for transportation in origin_transportations) <= const)\n",
    "            n_constraint +=1\n",
    "\n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "598cfa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation by month and product - lower bound\n",
    "def make_restriction_supply_by_product_lower(model, record, bandwidth, supply, y, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_product(b, match_brand_product, match_brand_number, match_product_brand, match_number_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'] == product_name)]['supply'])\n",
    "            \n",
    "            if o in origins_with_inf_supply:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "\n",
    "                # Add a restriction on supply >= lower_const\n",
    "                const *= constants['PERCENT_LOADING']\n",
    "                model.constraints.add(sum(y[transportation.get(\"var_name\")] for transportation in origin_transportations) >= const)\n",
    "                n_constraint +=1 \n",
    "\n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c01c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make restriction on supply by sum of all products - lower bound\n",
    "def make_restriction_supply_by_all_products_lower(model, record, supply, y, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    # brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    brands_list = [brand for brand in record.values()]\n",
    "    origins = []\n",
    "    \n",
    "    for brand in brands_list:\n",
    "        origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "    origins = list(set(origins))\n",
    "        \n",
    "    for o in origins:\n",
    "        if o in origins_with_inf_supply:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            transportations_list = []\n",
    "            for brand in brands_list:\n",
    "                transportations_list += get_brand_transportations(brand)            \n",
    "            \n",
    "                            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            const = float(supply[(supply['origin'] == o)]['supply'].sum())\n",
    "            const *= constants['PERCENT_LOADING']\n",
    "            \n",
    "            # Add a restriction on supply >= lower_const\n",
    "            model.constraints.add(sum(y[transportation.get(\"var_name\")] for transportation in origin_transportations) >= const)\n",
    "            n_constraint +=1\n",
    "    \n",
    "    return model, n_constraint, model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c10ac216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_Name(row):\n",
    "    return 'y_P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])), int(row[\"point\"]), int(row[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "079da918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df, model):\n",
    "    [*o] = df.apply(lambda row: create_dummy_Name(row), axis=1)\n",
    "    df_dummy = pd.DataFrame(o, columns=['dummy_Name', 'point', 'origin'])\n",
    "    df_dummy = df_dummy.reset_index()\n",
    "    df_dummy = df_dummy.drop_duplicates(subset=['dummy_Name', 'point', 'origin'])    \n",
    "    df_dummy.reset_index(inplace=True)\n",
    "    df_dummy.drop(columns=['index', 'level_0'], inplace=True)\n",
    "    \n",
    "    model.dummies = Var(range(len(df_dummy)), within=Binary)\n",
    "    \n",
    "    return df_dummy, model.dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c1a4afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points - origins dictionary\n",
    "def create_points_dict(df):\n",
    "    points_dict = {}\n",
    "    for p in list(df['point'].unique()):\n",
    "        origins_available = list(df[df['point'] == p]['origin'].unique())\n",
    "        if points_dict.get(p) == None:\n",
    "            points_dict[p] = origins_available\n",
    "    return points_dict\n",
    "\n",
    "points_dict = create_points_dict(df_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3252279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_dummy(record, model, y, points_dict, df_dummy, dummies_var, n_constraint):\n",
    "    \n",
    "    transportations = get_transportations(record)\n",
    "\n",
    "    #model.dummies = Var(range(len(df_dummy)), domain=Integers, bounds=(0, 1.))\n",
    "    \n",
    "    for p in points_dict.keys():\n",
    "        \n",
    "        for o in points_dict[p]:\n",
    "            \n",
    "            po_transportations = [transportation for transportation in transportations if transportation.get('origin') == o and transportation.get('point') == p]\n",
    "\n",
    "            df_d = df_dummy[(df_dummy['point'] == p) & (df_dummy['origin'] == o) ]\n",
    "            \n",
    "            # Restriction (...) <= M * Y_PnOm\n",
    "            dummy_index = int(df_d.index.values)\n",
    "            transportations_x = [y[i] for i in [transportation.get('var_name') for transportation in po_transportations]]\n",
    "            model.constraints.add(sum(transportations_x) <= constants['M']  * dummies_var[dummy_index])\n",
    "            n_constraint += 1\n",
    "\n",
    "    for p in points_dict.keys():\n",
    "        \n",
    "        df_d = df_dummy[df_dummy['point'] == p].index\n",
    "        # Restriction (y_PnOm1 + y_PnOm2 + ...) == 1 \n",
    "        model.constraints.add(sum([dummies_var[i] for i in np.array(df_d)]) == 1)\n",
    "        n_constraint +=1\n",
    "\n",
    "    return model, n_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e864302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы PYOMO:  13.356533765792847\n"
     ]
    }
   ],
   "source": [
    "pyomo_start = time.time()\n",
    "\n",
    "model, obj_expr, model.x = define_problem(df_reorganized)\n",
    "\n",
    "df_dummy, model.dummies = create_dummy(df_reorganized, model)\n",
    "\n",
    "model, n_constraint, model.x = make_restriction_demand(brand_info_map, model, demand, model.x, brands)\n",
    "\n",
    "if constants['UPPER_BOUND'] == 'group':\n",
    "    model, n_constraint, model.x = make_restriction_supply_by_group_upper(model, brand_info_map, bandwidth_subset, supply, model.x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint)\n",
    "elif constants['UPPER_BOUND'] == 'product':\n",
    "    make_restriction_supply_by_product_upper(model, brand_info_map, bandwidth_subset, supply, model.x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint)\n",
    "\n",
    "if constants['LOWER_BOUND'] == 'group':\n",
    "    make_restriction_supply_by_group_lower(model, brand_info_map, bandwidth_subset, supply, model.x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint)\n",
    "elif constants['LOWER_BOUND'] == 'product':\n",
    "    make_restriction_supply_by_product_lower(model, brand_info_map, bandwidth_subset, supply, model.x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint)\n",
    "elif constants['LOWER_BOUND'] == 'all producs':\n",
    "    make_restriction_supply_by_all_products_lower(model, brand_info_map, supply, model.x, brands, n_constraint)\n",
    "    \n",
    "model, n_constraint = make_restriction_dummy(brand_info_map, model, model.x, points_dict, df_dummy, model.dummies, n_constraint)\n",
    "\n",
    "pyomo_end = time.time()\n",
    "print('Время ввода ограничений: ', pyomo_end-pyomo_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79f55c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, df):\n",
    "    solver = SolverFactory('cbc.exe')\n",
    "    result = solver.solve(model)\n",
    "    print(result)\n",
    "    x_opt = [round(model.x[i].value, 3) for i in model.x]\n",
    "    c = np.array(df['cost'])\n",
    "    print('Cost: ', sum(x_opt * c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "361bf7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: \n",
      "- Lower bound: -inf\n",
      "  Upper bound: inf\n",
      "  Number of objectives: 1\n",
      "  Number of constraints: 4315\n",
      "  Number of variables: 7074\n",
      "  Sense: unknown\n",
      "Solver: \n",
      "- Status: ok\n",
      "  Message: cbc 2.10.7\\x3a optimal solution; 0 simplex iterations\n",
      "  Termination condition: optimal\n",
      "  Id: 0\n",
      "  Error rc: 0\n",
      "  Time: 3.5086231231689453\n",
      "Solution: \n",
      "- number of solutions: 0\n",
      "  number of solutions displayed: 0\n",
      "\n",
      "Cost:  182427606.13854608\n",
      "Время работы PYOMO:  27.909873962402344\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(model, df_reorganized)\n",
    "    \n",
    "    pyomo_end = time.time()\n",
    "    print('Время работы PYOMO: ', pyomo_end-pyomo_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
