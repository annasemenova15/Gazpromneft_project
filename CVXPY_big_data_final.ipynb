{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a7141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Install the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import yaml\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad28358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SettingWithCopyWarning \n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b99ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    try:\n",
    "        with open('config_file.yaml') as f:\n",
    "            global constants\n",
    "            constants = yaml.safe_load(f)\n",
    "    except OSError as e:\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1272c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "# File name is specified in config file\n",
    "data_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='data', engine='pyxlsb')\n",
    "real_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='Real', engine='pyxlsb')\n",
    "bandwidth_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='PS', engine='pyxlsb')\n",
    "match_input = pd.read_excel(constants['INPUT_FILE_NAME'], sheet_name='match', engine='pyxlsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d43989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets to implement further changes\n",
    "data = data_input.copy()\n",
    "real = real_input.copy()\n",
    "bandwidth = bandwidth_input.copy()\n",
    "match = match_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe87b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict of names on a spreadsheets that we are going to use\n",
    "names = {\"Тариф\" : \"cost\",\n",
    "        \"Плечо\" : \"distance\",\n",
    "        \"Дата\" : \"date\",\n",
    "        \"НБ\" : \"origin\",\n",
    "        \"ОУ\" : \"point\",\n",
    "        \"НП\" : \"brand\",\n",
    "        \"НП_ПС\" : \"product\",\n",
    "        \"Объем\" : \"volume\",\n",
    "        \"reg\": \"region\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b13d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the names in dataframes\n",
    "def rename_columns(df_list, names):\n",
    "    for df in df_list:\n",
    "         df.rename(columns=names, inplace=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4990c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, real, bandwidth, match = rename_columns([data, real, bandwidth, match], names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556f552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated; will raise an error if there are duplicates\n",
    "assert data[data.duplicated(subset = ['point', 'origin', 'region', 'brand', 'date'])].empty == True\n",
    "assert real[real.duplicated(subset = ['point', 'brand', 'date'])].empty == True\n",
    "assert bandwidth[bandwidth.duplicated(subset = ['origin', 'product', 'date'])].empty == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5886a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make subset for the concrete time period\n",
    "def select_time_period(df):\n",
    "    df_subset = df[df['date'] == constants['MONTH']]\n",
    "    return df_subset\n",
    "\n",
    "# Make subset for the concrete region - ONLY FOR EXPERIMENTS, IN THE FINAL VERSION ALL REGIONS GO TOGETHER\n",
    "def select_region(df):\n",
    "    regions_to_select = []\n",
    "    \n",
    "    for region_number in constants['REGION']:\n",
    "        region_name = 'Регион ' + str(region_number)\n",
    "        regions_to_select.append(region_name)\n",
    "        \n",
    "    if 'region' in df.columns:\n",
    "        df = df[(df['region'].isin(regions_to_select))]\n",
    "    return df\n",
    "    \n",
    "# Adjust datatypes. Enumerate oilbases and petrol stations      \n",
    "def adjust_datatypes(df_list):\n",
    "    df_new = []\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    for df in df_list:\n",
    "        if 'origin' in df.columns:\n",
    "            df = df.replace({\"origin\": oilbases_dict})\n",
    "        if 'point' in df.columns:\n",
    "            df['point'] = df['point'].map(lambda x: int(x.strip('АЗС ')))\n",
    "        df_new.append(df)\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99bace36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes to dataframes\n",
    "def apply_changes_dfs(data, real, bandwidth, match):\n",
    "    \n",
    "    data_subset = select_time_period(data)\n",
    "    real_subset = select_time_period(real)\n",
    "    bandwidth_subset = select_time_period(bandwidth)\n",
    "\n",
    "    data_subset = select_region(data_subset)\n",
    "\n",
    "    data_subset, real_subset, bandwidth_subset = adjust_datatypes([data_subset, real_subset, bandwidth_subset])\n",
    "    data_subset['cost'] = data_subset['cost'].round(4)\n",
    "    \n",
    "    return data_subset, real_subset, bandwidth_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50bd659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset, real_subset, bandwidth_subset = apply_changes_dfs(data, real, bandwidth, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86705a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brand-product dict\n",
    "def create_brand_product_dict(df):\n",
    "    match_brand_product = dict(zip(df['brand'], df['product']))\n",
    "    \n",
    "    match_product_brand = dict()\n",
    "    for key, value in match_brand_product.items():\n",
    "        match_product_brand.setdefault(value, list()).append(key)\n",
    "    return match_brand_product, match_product_brand\n",
    "\n",
    "# Create numeration dict and inverted dict\n",
    "def create_numeration_dict(df, parameter):\n",
    "    match_dict = dict(enumerate(df[parameter]))\n",
    "    inv_dict = {v: k for k, v in match_dict.items()}\n",
    "    return match_dict, inv_dict\n",
    "\n",
    "# Create numeration dict and inverted dict\n",
    "def create_prod_numeration_dict(df, parameter):\n",
    "    match_dict = dict(enumerate(df[parameter].unique()))\n",
    "    inv_dict = {v: k for k, v in match_dict.items()}\n",
    "    return match_dict, inv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734f9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 6 dictionaries (brand-product, brand-number, product-number, and inverted)\n",
    "match_brand_product, match_product_brand = create_brand_product_dict(match)\n",
    "match_brand_number, match_number_brand = create_numeration_dict(match,'brand')\n",
    "match_product_number, match_number_product = create_prod_numeration_dict(match,'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25063419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create name of variable\n",
    "def create_var_Name(row):\n",
    "    var_name = 'P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])) +  '_brand_' + str(int(row[\"brand_number\"]))\n",
    "    return var_name\n",
    "\n",
    "# Reorganize the data. Select only specified columns, enumerate brands and products\n",
    "def reorganize_df(df, columns_to_keep, match_number_brand, match_number_product):\n",
    "    df_reorganized = df.reset_index().loc[:, columns_to_keep]\n",
    "    df_reorganized['brand_number'] = df_reorganized['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    df_reorganized['product_number'] = df_reorganized['product'].map(lambda x: match_number_product.get(x))\n",
    "    \n",
    "    return df_reorganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fcaa7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['origin', 'point', 'brand', 'date', 'product', 'cost', 'region']\n",
    "df_reorganized = reorganize_df(data_subset, columns_to_keep, match_number_brand, match_number_product)\n",
    "\n",
    "# Create a name variable\n",
    "df_reorganized['var_Name'] = df_reorganized.apply(lambda row: create_var_Name(row), axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5a7466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demand and supply dataframes\n",
    "# Demand - volume of each product needed to be transported to the point\n",
    "# Supply - volume of each product available on the origin\n",
    "\n",
    "def create_demand_supply_dfs(real, bandwidth):\n",
    "    demand = real[['point', 'brand', 'product', 'volume', 'date']]\n",
    "    demand.rename(columns={'volume':'demand'}, inplace=True)\n",
    "    demand['brand_number'] = demand['brand'].map(lambda x: match_number_brand.get(x))\n",
    "    demand['product_number'] = demand['product'].map(lambda x: match_number_product.get(x))\n",
    "    demand['demand'] = demand['demand'].round(4)\n",
    "    \n",
    "    supply = bandwidth[['origin', 'product', 'volume', 'date']]\n",
    "    supply.rename(columns={'volume':'supply'}, inplace=True)\n",
    "    supply['product_number'] = supply['product'].map(lambda x: match_number_product.get(x))\n",
    "    supply['supply'] = supply['supply'].round(4)\n",
    "    \n",
    "    return demand, supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6bc5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, supply = create_demand_supply_dfs(real_subset, bandwidth_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe5cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit demand and supply with only needed origins and points\n",
    "supply = supply[supply['origin'].isin(df_reorganized.origin.unique())]\n",
    "demand = demand[demand['point'].isin(df_reorganized.point.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9accd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "df_reorganized_trans = df_reorganized.copy()\n",
    "\n",
    "# Check for where ALL volumes equals == 0 \n",
    "df_trans= supply[supply['supply'] <= 0][['origin', 'product_number']]\n",
    "origins_zero_volume = set(zip(df_trans.origin, df_trans.product_number))\n",
    "\n",
    "pairs_origins_products_to_delete = []\n",
    "pairs_points_brands_to_delete = []\n",
    "\n",
    "# Filter df_reogranized\n",
    "for _, row in df_reorganized.iterrows():\n",
    "\n",
    "    origin, point, product, brand = row['origin'], row['point'], row['product_number'], row['brand_number']\n",
    "    \n",
    "    if supply[(supply['origin'] == origin) & (supply['product_number'] == product)].empty:\n",
    "        pairs_origins_products_to_delete.append((origin, product))\n",
    "\n",
    "    if demand[(demand['point'] == point) & (demand['brand_number'] == brand)].empty:\n",
    "        pairs_points_brands_to_delete.append((point, brand))\n",
    "\n",
    "pairs_origins_products_to_delete = set(pairs_origins_products_to_delete)\n",
    "pairs_points_brands_to_delete = set(pairs_points_brands_to_delete)\n",
    "\n",
    "# Update origins to delete\n",
    "pairs_origins_products_to_delete.update(origins_zero_volume)\n",
    "\n",
    "df_reorganized_trans['origin_product'] = list(zip(df_reorganized_trans.origin, df_reorganized_trans.product_number))\n",
    "df_reorganized_trans['point_brand'] = list(zip(df_reorganized_trans.point, df_reorganized_trans.brand_number))\n",
    "  \n",
    "df_reorganized_trans = df_reorganized_trans.drop(df_reorganized_trans[df_reorganized_trans['origin_product'].isin(pairs_origins_products_to_delete)].index)\n",
    "df_reorganized_trans = df_reorganized_trans.drop(df_reorganized_trans[df_reorganized_trans['point_brand'].isin(pairs_points_brands_to_delete)].index)\n",
    "   \n",
    "        \n",
    "# Reassign df\n",
    "df_reorganized = df_reorganized_trans\n",
    "df_reorganized = df_reorganized.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9d036c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53802, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reorganized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0e672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1725aeac",
   "metadata": {},
   "source": [
    "# CVXPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "770e9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = df_reorganized['brand_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "115c40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_info_map = {}\n",
    "\n",
    "def make_brand(brand_id, name):\n",
    "    return {'name': name, 'id': brand_id, 'product_transportations': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "080183f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transportation(origin, point, cost, var_name):\n",
    "    return {'origin': origin, 'point': point, 'cost': cost, 'var_name': var_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0f31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transportation_to_brand(brand, product_id, transportation):\n",
    "    if brand['product_transportations'].get(product_id) == None:\n",
    "        brand['product_transportations'][product_id] = [transportation]\n",
    "        return brand\n",
    "    \n",
    "    brand['product_transportations'].get(product_id).append(transportation)\n",
    "\n",
    "    return brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "418fa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row_to_map(brand_map, row, index):\n",
    "    brand_id = row['brand_number']\n",
    "    \n",
    "    if brand_map.get(brand_id) == None:\n",
    "        brand_map[brand_id] = make_brand(brand_id, row['brand'])\n",
    "        \n",
    "    brand_item = brand_map.get(brand_id)\n",
    "    product_id = row['product_number']\n",
    "    \n",
    "    transportation = make_transportation(row['origin'], row['point'], row['cost'], index);\n",
    "    brand_map[brand_id] = add_transportation_to_brand(brand_item, product_id, transportation)\n",
    "    \n",
    "    return brand_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89528ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_reorganized.iterrows():\n",
    "    brand_info_map = append_row_to_map(brand_info_map, row, i)\n",
    "\n",
    "json_formatted_str = json.dumps(brand_info_map, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89877145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dicts for groups - either D (diesel) or P (petrol)\n",
    "def make_match_dicts(match_brand_product):\n",
    "    \n",
    "    match_brand_group = dict()\n",
    "    match_product_group = dict()\n",
    "\n",
    "    for k,v in match_brand_product.items():\n",
    "        if \"ДТ\" in v:\n",
    "            match_brand_group[k] = \"D\"\n",
    "            match_product_group[v] = \"D\"\n",
    "        \n",
    "        elif (\"АИ\" in v) | (\"Аи\" in v):\n",
    "            match_brand_group[k] = \"P\"\n",
    "            match_product_group[v] = \"P\"\n",
    "\n",
    "    match_group_brand = dict()\n",
    "\n",
    "    for k,v in match_brand_group.items():\n",
    "        match_group_brand.setdefault(v, list()).append(k)\n",
    "    \n",
    "    \n",
    "    match_group_product = dict()\n",
    "\n",
    "    for k,v in match_product_group.items():\n",
    "        match_group_product.setdefault(v, list()).append(k)\n",
    "    \n",
    "    return match_brand_group, match_product_group, match_group_brand, match_group_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb251f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_brand_group, match_product_group, match_group_brand, match_group_product = make_match_dicts(match_brand_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca08dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different products\n",
    "def merge_supply_by_product(brand_number, match_brand_product, match_brand_number, match_product_brand, match_number_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    product_name = match_brand_product[brand_name]\n",
    "    brands_overlap_names = match_product_brand[product_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff3bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different groups\n",
    "def merge_supply_by_group(brand_number, match_brand_number, match_number_brand, match_brand_group, match_group_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product group - P or D\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    group_name = match_brand_group[brand_name]\n",
    "    brands_overlap_names = match_group_brand[group_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1249dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for dividing supply between different brands\n",
    "def merge_supply(brand_number, match_brand_product, match_brand_number, match_product_brand, match_number_brand):\n",
    "    \"\"\"This function returns a set of brands' numbers that are produced from the same product\"\"\"\n",
    "    brand_name = match_brand_number[brand_number]\n",
    "    product_name = match_brand_product[brand_name]\n",
    "    brands_overlap_names = match_product_brand[product_name]\n",
    "    brands_overlap_numbers = set(match_number_brand.get(item) for item in brands_overlap_names)\n",
    "\n",
    "    return brands_overlap_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07a95405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique points inside each brand\n",
    "def extract_unique_points_of_brand(brand):\n",
    "    points = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            points.append(transportation.get('point'))\n",
    "\n",
    "    points = list(set(points))\n",
    "    \n",
    "    return points\n",
    "\n",
    "# Get the list of unique origins inside each brand\n",
    "def extract_unique_origins_of_brand(brand):\n",
    "    origins = []\n",
    "    for transportations in brand.get('product_transportations').values():\n",
    "        for transportation in transportations:\n",
    "            origins.append(transportation.get('origin'))\n",
    "\n",
    "    origins = list(set(origins))\n",
    "    \n",
    "    return origins\n",
    "\n",
    "# Extract the transportation of products from map dictionary\n",
    "def get_brand_transportations(brand):\n",
    "    brand_transpotrations = []\n",
    "    for product_id in brand.get('product_transportations').keys():\n",
    "        for transportation in brand.get('product_transportations').get(product_id):\n",
    "            brand_transpotrations.append(transportation)\n",
    "                \n",
    "    return brand_transpotrations\n",
    "\n",
    "# Get the list of unique origins (overall)\n",
    "def extract_unique_origins(brand_map):\n",
    "    origins = []\n",
    "    for brand in brand_map.values():\n",
    "        origins = origins + extract_unique_origins_of_brand(brand)\n",
    "\n",
    "    return list(set(origins))\n",
    "\n",
    "# Get the list of unique points (overall)\n",
    "def extract_unique_points(brand_map):\n",
    "    points = []\n",
    "    for brand in brand_map.values():\n",
    "        points = points + extract_unique_points_of_brand(brand)\n",
    "        \n",
    "    return list(set(points))\n",
    "\n",
    "# Get transportations of concrete brand\n",
    "def get_transportations(brand_map):\n",
    "    transportations = []\n",
    "    \n",
    "    for brand in brand_map.values():\n",
    "        transportations = transportations + get_brand_transportations(brand)\n",
    "        \n",
    "    return transportations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb6238a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_problem(df):\n",
    "    x = cp.Variable(len(df), nonneg = True)\n",
    "    c = np.array(df['cost'])\n",
    "    objective = cp.Minimize(c.T @ x)\n",
    "    \n",
    "    return x, objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b83a54",
   "metadata": {},
   "source": [
    "#### Define restriction #1: demand equals const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa19466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_demand(record, brands, x, demand):\n",
    "    n_constraint = 1\n",
    "    constraints = []\n",
    "    \n",
    "    for brand_id in brands:\n",
    "        brand = record.get(brand_id);\n",
    "        points = extract_unique_points_of_brand(brand)\n",
    "    \n",
    "        for p in points:\n",
    "            transportations = get_brand_transportations(brand)\n",
    "            brand_point_transpotrations = [transportation for transportation in transportations if transportation.get('point') == p]\n",
    "            \n",
    "            const = float(demand[(demand['point'] == p) & (demand['brand_number'] == brand_id)]['demand'])\n",
    "            transportations_x = [x[transportation.get('var_name')] for transportation in brand_point_transpotrations]\n",
    "            constraints.append(cp.sum(transportations_x) == const)\n",
    "            n_constraint +=1\n",
    "        \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83561da8",
   "metadata": {},
   "source": [
    "#### Define restriction #2: supply less or equal than const;  restriction #4: supply greater or equal to const * percent_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93b70362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make restriction on the supply (concrete volume of product available on origin)\n",
    "# Limitations by month, and by group S, D - upper bound\n",
    "def make_restriction_supply_by_group_upper(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    #origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_group(b, match_brand_number, match_number_brand, match_brand_group, match_group_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            group_name = match_product_group[product_name]\n",
    "            products_share_group = match_group_product[group_name]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'].isin(products_share_group))]['supply'].sum())\n",
    "            \n",
    "            # Add a restriction on supply <= upper_const\n",
    "            transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "            constraints.append(cp.sum(transportation_x) <= const)\n",
    "            n_constraint +=1  \n",
    "                \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a5f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make restriction on supply (restriction on lower percentage of loading)\n",
    "# Limitation by month, group D,and S - only lower bound\n",
    "def make_restriction_supply_by_group_lower(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_group(b, match_brand_number, match_number_brand, match_brand_group, match_group_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            group_name = match_product_group[product_name]\n",
    "            products_share_group = match_group_product[group_name]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'].isin(products_share_group))]['supply'].sum())            \n",
    "            \n",
    "            if o in origins_with_inf_supply:\n",
    "                continue       \n",
    "\n",
    "            else:\n",
    "\n",
    "                # Add a restriction on supply >= lower_const\n",
    "                const *= constants['PERCENT_LOADING']\n",
    "                transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "                constraints.append(cp.sum(transportation_x) >= const)\n",
    "                n_constraint +=1 \n",
    "                    \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a9b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation by month, group S, D - upper + lower\n",
    "def make_restriction_supply_by_group(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    #origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_group(b, match_brand_number, match_number_brand, match_brand_group, match_group_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            group_name = match_product_group[product_name]\n",
    "            products_share_group = match_group_product[group_name]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'].isin(products_share_group))]['supply'].sum())\n",
    "            \n",
    "            \n",
    "            if o in origins_with_inf_supply:\n",
    "                # Add a restriction on supply <= upper_const\n",
    "                transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "                constraints.append(cp.sum(transportation_x) <= const)\n",
    "                n_constraint +=1           \n",
    "\n",
    "            else:\n",
    "                # Add a restriction on supply <= upper_const\n",
    "                transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "                constraints.append(cp.sum(transportation_x) <= const)\n",
    "                n_constraint +=1            \n",
    "\n",
    "                # Add a restriction on supply >= lower_const\n",
    "\n",
    "                const *= constants['PERCENT_LOADING']\n",
    "                transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "                constraints.append(cp.sum(transportation_x) >= const)\n",
    "                n_constraint +=1 \n",
    "                   \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de829c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation by month and product - upper bound\n",
    "def make_restriction_supply_by_product_upper(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    #origins_with_inf_supply = list(bandwidth[bandwidth['volume'] == np.inf]['origin'].unique())\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_product(b, match_brand_product, match_brand_number, match_product_brand, match_number_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "            \n",
    "            \n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'] == product_name)]['supply'])\n",
    "            \n",
    "            # Add a restriction on supply <= upper_const\n",
    "            transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "            constraints.append(cp.sum(transportation_x) <= const)\n",
    "            n_constraint +=1 \n",
    "            \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd0aad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation by month and product - lower bound\n",
    "def make_restriction_supply_by_product_lower(constraints, record, bandwidth, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint):\n",
    "    # Set for storing already processed brands \n",
    "    brands_accounted_for = set()\n",
    "    \n",
    "    # Store origin with infinite supply in a separate list\n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    for b in brands:\n",
    "        if b in brands_accounted_for:\n",
    "            continue\n",
    "        \n",
    "        brands_overlap_numbers = merge_supply_by_product(b, match_brand_product, match_brand_number, match_product_brand, match_number_brand)\n",
    "        brands_accounted_for.update(brands_overlap_numbers)\n",
    "\n",
    "        brands_list = [brand for brand in record.values() if brand.get('id') in brands_overlap_numbers]\n",
    "\n",
    "        origins = []\n",
    "        for brand in brands_list:\n",
    "            origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "        origins = list(set(origins))\n",
    "        \n",
    "        transportations_list = []\n",
    "        for brand in brands_list:\n",
    "            transportations_list += get_brand_transportations(brand)\n",
    "\n",
    "        for o in origins:\n",
    "            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "            product_name = match_brand_product[match_brand_number[b]]\n",
    "            const = float(supply[(supply['origin'] == o) & (supply['product'] == product_name)]['supply'])\n",
    "            \n",
    "            if o in origins_with_inf_supply:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "\n",
    "                # Add a restriction on supply >= lower_const\n",
    "                const *= constants['PERCENT_LOADING']\n",
    "                transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "                constraints.append(cp.sum(transportation_x) >= const)\n",
    "                n_constraint +=1\n",
    "\n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46cf9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make restriction on supply by sum of all products - lower bound\n",
    "def make_restriction_supply_by_all_products_lower(constraints, record, supply, x, brands, n_constraint):\n",
    "    \n",
    "    number = 0\n",
    "    oilbases_dict = dict()\n",
    "\n",
    "    for i in bandwidth['origin'].unique():\n",
    "        oilbases_dict[i] = number\n",
    "        number+=1\n",
    "        \n",
    "    origins_with_inf_supply = set(oilbases_dict.values()).difference(constants['ORIGINS_TO_CONTROL'])\n",
    "    \n",
    "    brands_list = [brand for brand in record.values()]\n",
    "    origins = []\n",
    "    \n",
    "    for brand in brands_list:\n",
    "        origins += extract_unique_origins_of_brand(brand)\n",
    "            \n",
    "    origins = list(set(origins))\n",
    "        \n",
    "    for o in origins:\n",
    "        if o in origins_with_inf_supply:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            transportations_list = []\n",
    "            for brand in brands_list:\n",
    "                transportations_list += get_brand_transportations(brand)            \n",
    "            \n",
    "                            \n",
    "            origin_transportations = [transportation for transportation in transportations_list if transportation.get('origin') == o]\n",
    "\n",
    "            const = float(supply[(supply['origin'] == o)]['supply'].sum())\n",
    "            \n",
    "            # Add a restriction on supply >= lower_const\n",
    "            const *= constants['PERCENT_LOADING']\n",
    "            transportation_x = [x[transportation.get(\"var_name\")] for transportation in origin_transportations]\n",
    "            constraints.append(cp.sum(transportation_x) >= const)\n",
    "            n_constraint +=1\n",
    "    \n",
    "    return constraints, n_constraint, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c5cbc",
   "metadata": {},
   "source": [
    "#### Define restriction #3: all brands for one point should come from the same origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44d47f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_Name(row):\n",
    "    return 'y_P' + str(int(row[\"point\"])) + 'O' + str(int(row[\"origin\"])), int(row[\"point\"]), int(row[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58b81ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \n",
    "    [*o] = df.apply(lambda row: create_dummy_Name(row), axis=1)\n",
    "    df_dummy = pd.DataFrame(o, columns=['dummy_Name', 'point', 'origin'])\n",
    "    df_dummy = df_dummy.reset_index()\n",
    "    df_dummy = df_dummy.drop_duplicates(subset=['dummy_Name', 'point', 'origin'])    \n",
    "    df_dummy.reset_index(inplace=True)\n",
    "    df_dummy.drop(columns=['index', 'level_0'], inplace=True)\n",
    "    \n",
    "    # Create dummies AFTER wrong indexes are deleted...\n",
    "    dummies_vars = cp.Variable(len(df_dummy), boolean=True)\n",
    "    \n",
    "    return df_dummy, dummies_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a469842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy, dummies_vars = create_dummy(df_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43b311c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_restriction_dummy(record, x, constraints, n_constraint, points_dict, dummies_vars, df_dummy):\n",
    "    \n",
    "    transportations = get_transportations(record)\n",
    "\n",
    "    for p in points_dict.keys():\n",
    "        \n",
    "        for o in points_dict[p]:\n",
    "            \n",
    "            po_transportations = [transportation for transportation in transportations if transportation.get('origin') == o and transportation.get('point') == p]\n",
    "            \n",
    "            df_d = df_dummy[(df_dummy['point'] == p) & (df_dummy['origin'] == o) ]\n",
    "            \n",
    "            # Restriction (...) <= M * Y_PnOm       \n",
    "            transportations_x = [x[transportation.get('var_name')] for transportation in po_transportations]\n",
    "            constraints.append(cp.sum(transportations_x) <= constants['M'] * dummies_vars[df_d.index])\n",
    "            n_constraint += 1\n",
    "            \n",
    "    for p in points_dict.keys():\n",
    "        \n",
    "        df_d = df_dummy[df_dummy['point'] == p]\n",
    "        # Restriction (y_PnOm1 + y_PnOm2 + ...) == 1 \n",
    "        constraints.append(cp.sum(dummies_vars[df_d.index]) == 1)\n",
    "        n_constraint += 1\n",
    "    \n",
    "    return constraints, n_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5d7bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points - origins dictionary\n",
    "def create_points_dict(df):\n",
    "    points_dict = {}\n",
    "    for p in list(df['point'].unique()):\n",
    "        origins_available = list(df[df['point'] == p]['origin'].unique())\n",
    "        if points_dict.get(p) == None:\n",
    "            points_dict[p] = origins_available\n",
    "    return points_dict\n",
    "\n",
    "points_dict = create_points_dict(df_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2eef3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315.3352372646332"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_start = time.time()\n",
    "\n",
    "x, objective = define_problem(df_reorganized)\n",
    "\n",
    "constraints, n_constraint, x = make_restriction_demand(brand_info_map, brands, x, demand)\n",
    "\n",
    "if constants['UPPER_BOUND'] == 'group':\n",
    "    constraints, n_constraint, x = make_restriction_supply_by_group_upper(constraints, brand_info_map, bandwidth_subset, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint)\n",
    "elif constants['UPPER_BOUND'] == 'product':\n",
    "    constraints, n_constraint, x = make_restriction_supply_by_product_upper(constraints, brand_info_map, bandwidth_subset, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint)\n",
    "\n",
    "if constants['LOWER_BOUND'] == 'group':\n",
    "    constraints, n_constraint, x = make_restriction_supply_by_group_lower(constraints, brand_info_map, bandwidth_subset, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, match_product_group, match_group_product, match_group_brand, match_brand_group, n_constraint)\n",
    "elif constants['LOWER_BOUND'] == 'product':\n",
    "    constraints, n_constraint, x = make_restriction_supply_by_product_lower(constraints, brand_info_map, bandwidth_subset, supply, x, match_brand_product, match_brand_number, match_product_brand, match_number_brand, brands, n_constraint)\n",
    "elif constants['LOWER_BOUND'] == 'all producs':\n",
    "    make_restriction_supply_by_all_products_lower(constraints, brand_info_map, supply, x, brands, n_constraint)\n",
    "    \n",
    "constraints, n_constraint = make_restriction_dummy(brand_info_map, x, constraints, n_constraint, points_dict, dummies_vars, df_dummy)\n",
    "\n",
    "cbc_end = time.time()\n",
    "\n",
    "# Time for restrictions insertion\n",
    "cbc_end - cbc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(problem):\n",
    "    cbc_start = time.time()\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    solver= problem.solve(cp.CBC, verbose=True, maximumSeconds=1800)\n",
    "    cbc_end = time.time()\n",
    "    print(cbc_end - cbc_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24662b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398f190",
   "metadata": {},
   "source": [
    "Below the results of model are represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7855c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb9581e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.3.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jun 01 10:49:06 AM: Your problem has 67894 variables, 20742 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 01 10:49:11 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 01 10:49:11 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 01 10:49:11 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 01 10:49:18 AM: Compiling problem (target solver=CBC).\n",
      "(CVXPY) Jun 01 10:49:18 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CBC\n",
      "(CVXPY) Jun 01 10:49:18 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jun 01 10:49:41 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jun 01 10:49:48 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jun 01 10:57:25 AM: Applying reduction CBC\n",
      "(CVXPY) Jun 01 10:57:35 AM: Finished problem compilation (took 5.036e+02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 01 10:57:35 AM: Invoking solver CBC  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 01 11:27:31 AM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Jun 01 11:27:31 AM: Optimal value: 8.467e+07\n",
      "(CVXPY) Jun 01 11:27:31 AM: Compilation took 5.036e+02 seconds\n",
      "(CVXPY) Jun 01 11:27:31 AM: Solver (including time spent in interface) took 1.796e+03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py:1385: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "problem = cp.Problem(objective, constraints)\n",
    "solver= problem.solve(cp.CBC, verbose=True, maximumSeconds=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e726ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23f600d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2306.140187740326"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time spent for model building solution\n",
    "(cbc_end - cbc_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
